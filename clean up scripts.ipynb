{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220408_study section members.csv\n"
     ]
    }
   ],
   "source": [
    "# consolidate all member list data:\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# need to revise to handle n files\n",
    "files = ['20220408_study section members.csv', '20220920_study section members.csv', '20230621_study section members.csv', '20240621_study section members.csv']\n",
    "print(files[0])\n",
    "\n",
    "df = pd.read_csv(files[0])\n",
    "for file in files[1:]:\n",
    "    df = pd.concat([df, pd.read_csv(file)])\n",
    "\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "df.to_csv(today+'_all reviewers.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up names in member list data (remove degrees)\n",
    "import pandas as pd\n",
    "\n",
    "file = '20240626_all reviewers.csv'\n",
    "\n",
    "data = pd.read_csv(file)\n",
    "\n",
    "# strategy: delete everything after the 2nd comma (1st comma used in lastname, firstname)\n",
    "def find_nth(haystack: str, needle: str, n: int) -> int:\n",
    "    start = haystack.find(needle)\n",
    "    while start >= 0 and n > 1:\n",
    "        start = haystack.find(needle, start+len(needle))\n",
    "        n -= 1\n",
    "    return start\n",
    "\n",
    "# clean up name, save in several forms\n",
    "data[\"Name_original\"] = data[\"Name\"]\n",
    "data[\"Name\"] = [name[:find_nth(name, ',', 2)].strip().replace('  ', ' ') for name in data[\"Name\"]]\n",
    "data[\"Lastname\"] = [name.split(',')[0] for name in data['Name']]\n",
    "data[\"First_and_middle\"] = [name.split(',')[1].strip() for name in data['Name']]\n",
    "data['Firstname'] = [name.split(' ')[0] for name in data['First_and_middle']]\n",
    "\n",
    "# keep only the start date if it's part of a range\n",
    "data[\"Date_original\"] = data[\"Date\"]\n",
    "data[\"Date\"] = [meeting[0:8] for meeting in data[\"Date\"]] \n",
    "\n",
    "# remove duplicates\n",
    "data = data.drop_duplicates(subset=[\"Name\",\"Date\",\"Section Abbreviation\"])\n",
    "\n",
    "# extract zipcode\n",
    "data['Zipcode'] = [info.split(' ')[-1] for info in data[data.columns[5:11]].apply(lambda x: ', '.join(x.dropna().astype(str)), axis=1)]\n",
    "\n",
    "data.to_csv(file[:-4]+'_cleaned.csv', index=False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter reviewer list by current UT affiliation, using a different NIH Commons List from KW\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Import with all names uppercase for easiest matching\n",
    "UT_PIs = pd.DataFrame(pd.read_csv('UT Austin All People with Commons Role_20240624KW.csv')[\"Name\"].str.upper()) # just grab Name column\n",
    "all_reviewers = pd.read_csv('20240626_all reviewers_cleaned.csv') # all columns (meeting info)\n",
    "\n",
    "UT_reviewers = all_reviewers.merge(UT_PIs)\n",
    "UT_reviewers = UT_reviewers.drop_duplicates(subset=[\"Name\",\"Date\",\"Section Abbreviation\"])\n",
    "\n",
    "today = datetime.today().strftime('%Y%m%d')\n",
    "UT_reviewers.to_csv(today+'_UT NIH reviewers_consolidated.csv', index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
